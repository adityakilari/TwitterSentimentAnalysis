1. The data set(Corona_NLP_test) contains Number of Rows: 3798 Number of Columns: 5, this is a twitter data and we mostly work on OriginalTweet
Column to understand the sentiment of the tweet.

2. The first step is to clean the data, I,e to identify the null values in the dataset and removing them, to identify the duplicate entries
In the dataset

3. Taking the OriginalTweet column as a new dataset and to apply some preprocessing steps to it
    	a. removing special characters
	b. removing URLS in the string
	c. converting to lowercase
	d. stopwords removal


4. Convert the text corpus into tokens using word tokenization
 
5. Counting the Word frequencies and plotting the top 10 words

6. Created the word clouds and plotted the result
	